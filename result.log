ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.
 _    ____    __  ___      __________  ____  ____         
| |  / / /   /  |/  /     / ____/ __ \/ __ \/ __ \        
| | / / /   / /|_/ /_____/ / __/ /_/ / /_/ / / / /  ______
| |/ / /___/ /  / /_____/ /_/ / _, _/ ____/ /_/ /  /_____/
|___/_____/_/  /_/      \____/_/ |_/_/    \____/          
                                                          
    ____  ___  ______________  _______   ________
   / __ \/   |/_  __/ ____/ / / /  _/ | / / ____/
  / /_/ / /| | / / / /   / /_/ // //  |/ / / __  
 / ____/ ___ |/ / / /___/ __  // // /|  / /_/ /  
/_/   /_/  |_/_/  \____/_/ /_/___/_/ |_/\____/   
                                                 
   __  ___   _______ __    ____  ________  __
  / / / / | / / ___// /   / __ \/_  __/ / / /
 / / / /  |/ /\__ \/ /   / / / / / / / /_/ / 
/ /_/ / /|  /___/ / /___/ /_/ / / / / __  /  
\____/_/ |_//____/_____/\____/ /_/ /_/ /_/   
                                             

Unsloth patched for VLMs GRPO training
ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!
==((====))==  Unsloth 2025.4.1: Fast Qwen2_5_Vl patching. Transformers: 4.49.0.
   \\   /|    NVIDIA A2. Num GPUs = 1. Max memory: 14.542 GB. Platform: Linux.
O^O/ \_/ \    Torch: 2.7.0+cu126. CUDA: 8.6. CUDA Toolkit: 12.6. Triton: 3.3.0
\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.30. FA2 = False]
 "-____-"     Free license: http://github.com/unslothai/unsloth
Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!
Unsloth: We now expect `per_device_train_batch_size` to be a multiple of `num_generations`.
We will change the batch size of 1 to the `num_generations` of 2
prompt length > max prompt length : truncating
